{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Stumbleupon dataset\n",
    "\n",
    "This data is stumbleupon links, and we are trying to see if they are evergreen or ephemeral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import statements\n",
    "# the standard stuff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import json\n",
    "import sklearn.feature_extraction.text as sktext\n",
    "import string\n",
    "import sklearn.naive_bayes as nb\n",
    "import sklearn.svm as svm\n",
    "\n",
    "import sklearn.cross_validation as cross_validation\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_loop(X, labels, model, K):\n",
    "    '''\n",
    "    Cross validation: for K iterations, split the data into train and test\n",
    "    sets, build a model, and return the mean AUC.\n",
    "    '''\n",
    "    \n",
    "    SEED = 15\n",
    "    mean_auc = 0.\n",
    "    for i in range(K):\n",
    "        X_train, X_cv, labels_train, labels_cv = cross_validation.train_test_split(\n",
    "            X, labels, test_size = 0.2,\n",
    "            random_state = i*SEED)\n",
    "        model.fit(X_train, labels_train)\n",
    "        preds = model.predict_proba(X_cv)[:,1]\n",
    "        auc = metrics.roc_auc_score(labels_cv, preds)\n",
    "        print(\"AUC (fold %d/%d): %f\" % (i + 1, K, auc))\n",
    "        mean_auc += auc\n",
    "    return mean_auc/K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2958, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>url</th>\n",
       "      <th>urlid</th>\n",
       "      <th>boilerplate</th>\n",
       "      <th>alchemy_category</th>\n",
       "      <th>alchemy_category_score</th>\n",
       "      <th>avglinksize</th>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <th>...</th>\n",
       "      <th>image_ratio</th>\n",
       "      <th>is_news</th>\n",
       "      <th>lengthyLinkDomain</th>\n",
       "      <th>linkwordscore</th>\n",
       "      <th>news_front_page</th>\n",
       "      <th>non_markup_alphanum_characters</th>\n",
       "      <th>numberOfLinks</th>\n",
       "      <th>numwords_in_url</th>\n",
       "      <th>parametrizedLinkRatio</th>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4646</td>\n",
       "      <td>http://sportsillustrated.cnn.com/2011_swimsuit...</td>\n",
       "      <td>7668</td>\n",
       "      <td>{\"title\":\"Kate Upton Swimsuit by Kikidoll 2011...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.158209</td>\n",
       "      <td>0.505917</td>\n",
       "      <td>0.428994</td>\n",
       "      <td>0.023669</td>\n",
       "      <td>...</td>\n",
       "      <td>1.014599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>547</td>\n",
       "      <td>338</td>\n",
       "      <td>4</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.053571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3110</td>\n",
       "      <td>http://lungcancercauses.org/infographics/how-t...</td>\n",
       "      <td>4836</td>\n",
       "      <td>{\"title\":\"How to Prevent Cancer for FREE Infog...</td>\n",
       "      <td>health</td>\n",
       "      <td>0.757862</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>467</td>\n",
       "      <td>http://www.melskitchencafe.com/2011/04/penne-w...</td>\n",
       "      <td>5920</td>\n",
       "      <td>{\"url\":\"melskitchencafe 2011 04 penne with roa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.794118</td>\n",
       "      <td>0.173410</td>\n",
       "      <td>0.086705</td>\n",
       "      <td>0.052023</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12792</td>\n",
       "      <td>173</td>\n",
       "      <td>7</td>\n",
       "      <td>0.052023</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>526</td>\n",
       "      <td>http://www.npr.org/blogs/thetwo-way/2009/09/ba...</td>\n",
       "      <td>1467</td>\n",
       "      <td>{\"title\":\"Aw Cutie Pie Sends Baseball Back Whe...</td>\n",
       "      <td>sports</td>\n",
       "      <td>0.381499</td>\n",
       "      <td>1.981308</td>\n",
       "      <td>0.581967</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.061475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1634</td>\n",
       "      <td>244</td>\n",
       "      <td>9</td>\n",
       "      <td>0.278689</td>\n",
       "      <td>0.095541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2194</td>\n",
       "      <td>http://www.buzzfeed.com/mjs538/the-10-worst-mo...</td>\n",
       "      <td>5964</td>\n",
       "      <td>{\"title\":\"The 10 Worst Moose Knuckles At The O...</td>\n",
       "      <td>sports</td>\n",
       "      <td>0.621481</td>\n",
       "      <td>1.381910</td>\n",
       "      <td>0.406863</td>\n",
       "      <td>0.057190</td>\n",
       "      <td>0.024510</td>\n",
       "      <td>...</td>\n",
       "      <td>2.478261</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10422</td>\n",
       "      <td>612</td>\n",
       "      <td>5</td>\n",
       "      <td>0.266340</td>\n",
       "      <td>0.067568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                url  urlid  \\\n",
       "0        4646  http://sportsillustrated.cnn.com/2011_swimsuit...   7668   \n",
       "1        3110  http://lungcancercauses.org/infographics/how-t...   4836   \n",
       "2         467  http://www.melskitchencafe.com/2011/04/penne-w...   5920   \n",
       "3         526  http://www.npr.org/blogs/thetwo-way/2009/09/ba...   1467   \n",
       "4        2194  http://www.buzzfeed.com/mjs538/the-10-worst-mo...   5964   \n",
       "\n",
       "                                         boilerplate alchemy_category  \\\n",
       "0  {\"title\":\"Kate Upton Swimsuit by Kikidoll 2011...              NaN   \n",
       "1  {\"title\":\"How to Prevent Cancer for FREE Infog...           health   \n",
       "2  {\"url\":\"melskitchencafe 2011 04 penne with roa...              NaN   \n",
       "3  {\"title\":\"Aw Cutie Pie Sends Baseball Back Whe...           sports   \n",
       "4  {\"title\":\"The 10 Worst Moose Knuckles At The O...           sports   \n",
       "\n",
       "   alchemy_category_score  avglinksize  commonlinkratio_1  commonlinkratio_2  \\\n",
       "0                     NaN     1.158209           0.505917           0.428994   \n",
       "1                0.757862     1.600000           0.300000           0.300000   \n",
       "2                     NaN     1.794118           0.173410           0.086705   \n",
       "3                0.381499     1.981308           0.581967           0.245902   \n",
       "4                0.621481     1.381910           0.406863           0.057190   \n",
       "\n",
       "   commonlinkratio_3          ...            image_ratio  is_news  \\\n",
       "0           0.023669          ...               1.014599      NaN   \n",
       "1           0.300000          ...              -1.000000      NaN   \n",
       "2           0.052023          ...              -1.000000      NaN   \n",
       "3           0.061475          ...               0.078014      1.0   \n",
       "4           0.024510          ...               2.478261      1.0   \n",
       "\n",
       "   lengthyLinkDomain  linkwordscore  news_front_page  \\\n",
       "0                  0             78              NaN   \n",
       "1                  0             30              0.0   \n",
       "2                  1              6              NaN   \n",
       "3                  0             55              0.0   \n",
       "4                  1             20              0.0   \n",
       "\n",
       "   non_markup_alphanum_characters  numberOfLinks  numwords_in_url  \\\n",
       "0                             547            338                4   \n",
       "1                             188             10                7   \n",
       "2                           12792            173                7   \n",
       "3                            1634            244                9   \n",
       "4                           10422            612                5   \n",
       "\n",
       "   parametrizedLinkRatio  spelling_errors_ratio  \n",
       "0               0.005917               0.053571  \n",
       "1               0.100000               0.062500  \n",
       "2               0.052023               0.111111  \n",
       "3               0.278689               0.095541  \n",
       "4               0.266340               0.067568  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data\n",
    "training_data = pd.read_csv(\"./data/train.csv\", na_values=\"?\")\n",
    "testing_data  = pd.read_csv(\"./data/test.csv\", na_values=\"?\")\n",
    "print(testing_data.shape)\n",
    "testing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC (fold 1/10): 0.852821\n",
      "AUC (fold 2/10): 0.850404\n",
      "AUC (fold 3/10): 0.853193\n",
      "AUC (fold 4/10): 0.870312\n",
      "AUC (fold 5/10): 0.863857\n",
      "AUC (fold 6/10): 0.860326\n",
      "AUC (fold 7/10): 0.876845\n",
      "AUC (fold 8/10): 0.879162\n",
      "AUC (fold 9/10): 0.877240\n",
      "AUC (fold 10/10): 0.844856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86290162535772086"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the goal is to create a bag of words model out of the data\n",
    "# basically reformat the data to only care about the body text data\n",
    "\n",
    "\n",
    "training_data_bow = [[item[2], json.loads(item[3])[\"body\"], item[-1]] for item in training_data.as_matrix()]\n",
    "\n",
    "tr_urlids = [x[0] for x in training_data_bow]\n",
    "tr_text = [x[1] if x[1] is not None else \"\" for x in training_data_bow]\n",
    "tr_label = [x[2] for x in training_data_bow]\n",
    "\n",
    "# remove punctuation and stop words\n",
    "punctuation_dict = dict((ord(char), None) for char in string.punctuation)\n",
    "tr_text_no_punc = [x.translate(punctuation_dict) for x in tr_text]\n",
    "\n",
    "\n",
    "# this was pretty much taken straight off the text tutorial on sklearn\n",
    "count_vec = sktext.CountVectorizer()\n",
    "tr_text_wc = count_vec.fit_transform(tr_text_no_punc)\n",
    "\n",
    "tfidf_tf = sktext.TfidfTransformer()\n",
    "tr_text_tfidf = tfidf_tf.fit_transform(tr_text_wc)\n",
    "\n",
    "# create and test the model\n",
    "model = nb.MultinomialNB()\n",
    "\n",
    "cv_loop(tr_text_tfidf, tr_label, model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2958\n",
      "2958\n",
      "2958\n",
      "(2958, 1)\n"
     ]
    }
   ],
   "source": [
    "# Well that looks good, lets fit the model completely and then make our predictions\n",
    "model.fit(tr_text_tfidf, tr_label)\n",
    "\n",
    "testing_data_bow = [[item[2], json.loads(item[3])[\"body\"]] for item in testing_data.as_matrix()]\n",
    "print(len(testing_data_bow))\n",
    "\n",
    "test_urlids = [x[0] for x in testing_data_bow]\n",
    "test_text = [x[1] if x[1] is not None else \"\" for x in testing_data_bow]\n",
    "\n",
    "print(len(test_urlids))\n",
    "print(len(test_text))\n",
    "\n",
    "test_text_no_punc = [x.translate(punctuation_dict) for x in test_text]\n",
    "\n",
    "test_text_wc = count_vec.transform(test_text_no_punc)\n",
    "\n",
    "test_tfidf_tf = sktext.TfidfTransformer()\n",
    "test_text_tfidf = test_tfidf_tf.fit_transform(test_text_wc)\n",
    "\n",
    "preds = model.predict_proba(test_text_tfidf)[:,1]\n",
    "\n",
    "# combine the predictions and url IDs into a pandas dataframe\n",
    "# Note: this is easy with Python's dictionaries, but make sure to set\n",
    "# the index to url ID (otherwise the column orders will be random. Reason=dictionaries are unordered)\n",
    "pred_df = pd.DataFrame({'label':preds, 'urlid': test_urlids}).set_index('urlid')\n",
    "print(pred_df.shape)\n",
    "pred_df.to_csv('evergreen_submission_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
